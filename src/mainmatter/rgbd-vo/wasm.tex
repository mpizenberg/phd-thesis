\chapter{Performant Web Applications}%
\label{cha:performant_web_applications}

\minitoc%

\section{A Brief History of Native Code in the Client}%
\label{sec:native_client}

Being able to run high performance code in the browser
unlocks many use cases, including scientific computing.
Yet, it remains a challenging task.
Resources often refers to this as ``native'' code
but the terminology is rather vague.
Depending on the context, it may have one of the following meanings,
\begin{enumerate}
\setlength\itemsep{-0.5em}
	\item code statically compiled directly to the target architecture and running from the browser,
	\item code compiled from a typical ``native'' language such as C or C++,
	\item or anything that is not generating JavaScript.
\end{enumerate}
The distinction between those and how they relate to ``native'' code
will be made clearer after a brief history of high performance code in browsers.

\subsection{Java Applets}%
\label{sub:java_applets}

In 1995, just four years after the birth of the Web,
the Java programming language was created.
It appeared with a companion technology called Java Applet,
designed to run Java applications in the browser.
The Java Virtual Machine (JVM) was hosted by browsers,
enabling much better performances than JavaScript at that time.
As an example, Brendon C. Glazer worked on interactive ray tracing
of VRML scenes with Java applets in 1999~\cite{Glazer1999InteractiveRT}.
Figure~\ref{fig:glazer-thesis} depicts how the applet would appear
in a Web page at that time.
Since 1998 Java applets have also had access to 3D hardware acceleration~\cite{Java3dAPISpec}
whereas JavaScript waited until 2011 for WebGL in HTML5 canvas.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{assets/img/glazer-thesis.jpg}
	\caption{Interactive ray tracing applet from Brendon C. Glazer master thesis (1999).}%
	\label{fig:glazer-thesis}
\end{figure}

On the down side, Java applets would break accessibility of the Web.
Screen readers would not be able to parse the content of the dedicated
applet area in the page.
The security model of Java applets was also quite risky.
Applets would have to get approved by a browser user and then gain rights
equivalent to a native application on your desktop.
Unfortunately, just like terms of service, most people just click ``agree''
and move on.
In addition, the Java Runtime Environment (JRE) has had hundreds of security
vulnerabilities~\cite{JreCve} in its lifetime.
This represents a serious security threat for browser vendors.
Java applets were eventually entirely removed from Java SE 11, in 2018.

\subsection{Flash}%
\label{sub:Flash}

In his ``History of Flash''~\cite{HistoryFlash}, Jonathan Gay retraces the early days of Flash.
In 1993, he, Charlie Jackson and Michelle Welsh founded FutureWave Software
but their initial vector drawing application did not draw much attention (pun intended).
After discussions at Siggraph 1995, the company decided to focus on a web animation
product named ``FutureSplash Animator''.
It gained reputation with Microsoft and Disney using it and as a consequence,
was acquired by Macromedia and rebranded ``Flash'' in 1996.

Contrary to Java applets, Flash use cases started very narrow.
It provided a simple and efficient solution to build and share animations on the web,
giving a visual advantage over pure HTML documents.
In year 2000, Flash 5 was released, with the ActionScript programming language,
bringing even more potential to Flash-based websites.
Two years later, in 2002, Flash 6 brought support for real-time messaging protocols,
enabling video and audio streaming capabilities.
This represents roughly 8 years until 2010 when such capabilities are also
supported through HTML5 in most browsers.
In the meantime, highly influencial projects shaped the Web thanks to Flash.
You may have heard of Chad Hurley, Steve Chen and Jawed Karim who launched
YouTube in 2005, based on Flash.

In spite of the many advantages of Flash and ActionScript over classic Web pages,
it also had similar flaws than Java applets.
In October 2000, usability consultant Jakob Nielsen published a short article
entitled ``Flash: 99\% Bad''~\cite{FlashBadNielsen} stating that
``Flash technology tends to discourage usability for three reasons:
it makes bad design more likely,
it breaks with the Web's fundamental interaction style,
and it consumes resources that would be better spent enhancing a site's core value.''
Apple also played a huge role in Flash decline.
In 2007 the iPhone launched without Flash support,
leading to Steve Jobs, then Apple CEO, writing in 2010 an oppen letter called
``Thoughts on Flash''~\cite{FlashJobs}
in which he explains why Flash was doomed to disappear.
Among those reasons, Flash is proprietary, going against open Web standards,
it has numerous security flaws~\cite{FlashCVE}, and is the number one reason Macs crash.

Consequently, with the advent of HTML5 surrounding technologies regarding multimedia capabilities,
and the improved performances of JavaScript, Flash became obsolete.
So in July 2017, Adobe announced end support of Flash in 2020.

\subsection{Google Native Client (NaCl)}%
\label{sub:nacl}

Java applets and Flash were never trully considered ``native''
since they involved third party virtual machines.
You would not compile your code directly to machine instructions
but to an intermediate bytecode representation for Java applets,
or just using a JIT compiler for ActionScript (Flash) code.
They provided however great performances improvements when compared
to JavaScript before 2008 and the arrival of JavaScript JIT compilers with the V8 engine.
But around 2009 and 2010, two new projects named Native Client (NaCl) and Emscripten
respectively emerged from research at Google and Mozilla.
We will hold on Emscripten for now and explain first what NaCl was about.

At this period of time, native code was already running in browsers,
usually via an old plugin interface called the ``Netscape Plugin API'' (NPAPI).
This is how the JVM, the Flash player or PDF readers for example
would be integrated in browsers.
So from the observation that the Web had trully become a rich multimedia platform,
and that native code was already running in browsers via plugins,
a team of Google engineers explored a way to generalize and improve security
of any native C or C++ code execution in browsers~\cite{yee2009native}.
This would in theory unlock high performances for any Web application.
But it would need a sandboxed and secure new set of APIs
to make sure that those applications would not execute any malicious code via the browser.
That is how the Native Client (NaCl) project,
and its associated API called Pepper Plugin API (PPAPI) started in 2009.
I'll make the assumption that you got the NaCl and pepper joke \ldots

The two main downsides of this approach are the security and portability concerns.
Even though NaCl code would run into a sandboxed environment,
enforcing both security and accessibility to classical desktop resources
requires a continuous effort from browser vendors,
now needing to secure two different sandboxed environment,
NaCl and JavaScript, instead of one.
Portability was also a concern since any NaCl code would need to be compiled
to all target architectures where the browser need to run.
In practice, only x86 intel architectures were fully supported,
going against the nature of the Web, supposed to run on all platforms.
This limitation was the reason for the birth of the Portable Native Client project.

Portable Native Client (PNaCl, pronounced like the word ``pinnacle'', you get this one?),
was a work by A. Donovan et al.~\cite{donovan2010pnacl} aiming at distributing
NaCl programs in an intermediate pre-compiled neutral instruction-set format,
preventing the need to compile directly to all target architectures.
Concretely, the format chosen was the Low-Level Virtual Machine (LLVM) bitcode.
Unfortunately, this intermediate representation bitcode is a fast moving target,
and retrocompatibility is not a main objective of the LLVM project.
It means that PNaCl code could become obsolete at a fast pace,
also a deal breaker for Web standards.
With the reluctance of other vendors to adopt a non-specified Google initiative,
and the appeal of another rising approach coming from Emscripten,
PNaCl was finally deprecated in 2017.

\subsection{Emscripten and asm.js}%
\label{sub:emscripten-asmjs}

Out of curiosity, Mozilla engineer Alon Zakai started to work around 2010
on a project to explore the limitations of compiling C++ code to JavaScript.
It was the start of the Emscripten project~\cite{zakai2011emscripten}.
Emscripten base idea consists in converting LLVM bitcode to JavaScript.
LLVM originated from the work of
Chris Lattner and Vikram Adve~\cite{lattner2004llvm} on a compiler framework
and an intermediate code representation, optimized for compiler transformations.
It reduces the language-architecture complexity from $\mathcal{O}(mn)$ to $\mathcal{O}(m+n)$
since languages do not need to compile to every target like x86 or Arm,
and instead can just target LLVM which in turn knows how to compile to each
instruction set architecture (ISA) as depicted in Figure~\ref{fig:llvm}.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{assets/img/llvm.pdf}
	\caption{LLVM Compiler Infrastructure}%
	\label{fig:llvm}
\end{figure}

After few iterations with the help of Luke Wagner, working on JavaScript compilation at Mozilla,
Emscripten was able to output JavaScript code running at roughly 2x to 4x native speed.
This specific subset of JavaScript was formalized under the name asm.js in 2013~\cite{herman2013asm}.
The asm.js code for a sum function is presented in Listing~\ref{lst:add-asmjs}.
As you can see, it makes use of JavaScript operations doing nothing,
like the bitwise-or with 0, except cohercing values to certain types.
You would not want to write asm.js code by hand, but for a compiler,
it enables certain kinds of optimizations not possible with traditional
hand-written JavaScript code.
Yet it is a strict subset of JavaScript and can still run in any browser,
whether or not they have a specialized handling of asm.js.

\lstinputlisting[%
	language=JavaScript,
	caption={Sum of two 32-bit integers in asm.js.},
	label={lst:add-asmjs}
]{assets/code/add-asm.js}

The performances without the need of any plugin convinced companies with huge
code bases to join the effort.
The Unreal game engine was ported, Autodesk AutoCAD~\cite{autocadweb}, Adobe Lightroom,
Facebook image compressions uploading code, OpenCV~\cite{taheri2018opencv} and many others.
With the success of Emscripten and asm.js as a proof of concept,
all major browser vendors came together to formalize a new specification
known today as WebAssembly.
Figure~\ref{fig:wasm-timeline} summarizes main events leading to the creation of WebAssembly.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{assets/img/wasm-timeline.pdf}
	\caption{Events releated to the birth of WebAssembly.}%
	\label{fig:wasm-timeline}
\end{figure}

\section{WebAssembly}%
\label{sec:WebAssembly}

WebAssembly, abreviated Wasm, is an instruction set with a binary format,
and a stack-based virtual machine able to execute those programs~\cite{haas2017bringing}.

\subsection{Relation to Previous Technologies}%
\label{sub:wasm_previous}

Just like Flash and Java applets, WebAssembly code
is executed by a virtual machine.
Similarly to NaCl, the Wasm runtime is sandboxed,
preventing it from accessing data outside of its context
and compromising the security of the underlying machine.
And as asm.js, Wasm does not require any plugin.
It has been developed as a Web standard and implemented
by all major Web browsers, desktop and mobile, since 2017.
Unlike asm.js however, Wasm is distributed in a binary format,
meaning it is more efficient to send over the network and to parse,
drastically reducing the loading time of Web pages.
WebAssembly has been built drawing lessons from the past and is going to endure
for the following reasons.

\begin{itemize}
	\item It is a Web standard and a collective effort from all browser vendors.
	\item It is the low level missing piece of the Web,
		complementing JavaScript where more control over performances is needed.
	\item It has strong security guaranties, and a sound type system~\cite{watt2018mechanising}.
	\item It theoretically enables any programming language to run on the Web.
\end{itemize}

\subsection{Compilation to WebAssembly}%
\label{sub:compile-wasm}

Currently WebAssembly does not provide a garbage collector.
Therefore, there are two main approaches to compile to WebAssembly.
If your programming language enables memory management at compile time,
such as C, C++ or Rust, the simplest way is to target LLVM intermediate representation.
Emscripten enables compilation to WebAssembly from C and C++.
Rust can either use Emscripten as a backend or directly the wasm32 target of LLVM.\@
Otherwise, if your programming language requires a runtime for features such as garbage collection,
the entire runtime needs to be ported to WebAssembly in addition the actual program.
This is for example the case of Blazor, a .NET (Microsoft) library
enabling the creation of Single Page Applications written in C\#.

\subsection{WebAssembly Minimum Viable Product (MVP)}%
\label{sub:wasm-mvp}

The first version of WebAssembly, initially released on March 2017,
is called a minimum viable product (MVP).
This consensus aimed at producing a simple yet functional specification and implementation
for all major browser vendors.
Concretely, the Wasm MVP offers roughly the same capabilities than asm.js.
It has only four types, integers and floating point numbers in 32 and 64 bits,
and manages memory as a unique contiguous block of bytes.
New features such as threads,
SIMD, exception handling, reference types, garbage collection or tail call optimization,
are currently being worked on and delayed to the after-MVP phase.

\subsection{WebAssembly Bright Future}%
\label{sub:wasm-future}

A common pun in WebAssembly communities is to describe it as ``neither Web, nor assembly''.
Although slightly caricatural, the WebAssembly specification does not require any Web component.
As a matter of fact, just like JavaScript broke out of the browser with Node,
many non-browser WebAssembly runtimes have already been created, such as Wasmer~\cite{wasmer}
and Wasmtime~\cite{wasmtime}.

Since Wasm is basically a performant sandboxed calculator,
interop capabilities with files or the network
must be provided in the form of imports and exports of a Wasm module.
In the browser, those are passed to the module at the initialization call from JavaScript.
But outside of the browser, as in Wasmer for example,
imports and exports have to be provided by the runtime environment.
If we want to be able to use the same Wasm module in those two different contexts,
we need to have a common interface specification,
which can have different implementations in each runtime environment.

In order to adress those points, the WebAssembly working group
is standardizing a system interface under the name
WebAssembly System Interface (WASI~\cite{wasi}) and a types interface
known as WebAssembly Interface Types~\cite{wait}.
As shown in the demonstration video available on YouTube~\cite{waitvideo},
it is now possible to create a Wasm library in Rust for example,
and then call it from the Web, Node, Rust, but even Python or any language
capable of embedding a WebAssembly runtime.

\subsection{Why this Matters for Research}%
\label{sub:matter-research}

A growing number of actors are worrying about research
reproducibility~\cite{claerbout1992electronic, buckheit1995wavelab}
in computational sciences.
Nick Barnes published an article on Nature News~\cite{barnes2010publish}
encouraging researchers to publish even bad code instead of none.

IPOL Journal~\cite{limare2011ipol}, Image Processing On Line, is an initiative supported by
the French space agency CNES and the European Research Council.
Its goal is to publish both precise algorithm descriptions and certified implementations,
and making them available on an online platform.
Due to performance constraints, they rejected most garbage collected languages
interpreted or based on virtual machines such as Python and Java,
and only accept Fortran, C and C++ implementations with strict portability requirements.
In order to mitigate security risks, authors are uniquely identified.
Exposure to malicious data, such as images uploaded by online users,
is reduced by system restrictions and careful examination of the source code during review.
WebAssembly would have been a perfect fit for this project if it had existed in 2010
since it provides a solution for secure, performant and portable code.

The Association for Computing Machinery (ACM) recently revised its
artifact review and badging policies~\cite{acm2018badging},
based on the International Vocabulary for Metrology.
A work is considered repeatable if the results are obtainable on multiple trials,
within the same team and experimental setup.
It is considered replicable if another team is capable of getting the same results
while reusing the provided artifact and same experimental setup.
Finally it is considered reproducible if the results can be reproduced
with different teams and experimental setup, without using the provided artifacts.
In accordance to these guidelines, ACM Multimedia, the ACM conference targetting multimedia
research, has setup a reproducibility review process,
based on companion papers~\cite{acmmmreproducibility}.
Companion papers are distinct from the main paper.
They must be provided with associated artifacts and describe precisely
how to replicate the findings of the associated original paper contribution.

Containarization of the development environment with tools such as Docker
is a new practice reducing dependency conflicts.
It has been picked up by the machine learning community,
especially when needing to use different versions of languages and tools
for deep learning tasks in separate projects.
Carl Boettiger even wrote a paper entitled
``An introduction to Docker for reproducible research''~\cite{boettiger2015introduction}
discribing the different aspects of computer environments preventing work reproducibility.
Yet, Solomon Hykes, the original author of Docker shared on twitter that
if WebAssembly and its system interface existed in 2008, he wouldn't have
needed to create Docker~\cite{hykes2019twitter}. ``That's how important it is'' as he said.

\section{C++ Portability Pitfalls}%
\label{sec:cpp_pitfalls}

Not every C or C++ project can be ported to WebAssembly.
There are three main factors of non portability,
Web limitations, no low level architecture specific code and no system dynamic linking.

\subsection{Web Limitations}%
\label{sub:web_limitations}

High performance code may rely on parallelization to speed up processing.
Due to security concerns, parallelization methods such as multithreading
or SIMD are currently a work in progress but not usable by default in browsers.

\subsection{Low Level Native or Architecture Specific Code}%
\label{sub:low_level_code}

Other high performance code may rely on architecture specific constraints.
For example, x86 assembly is not portable to other platforms.
Code requiring a big-endian physical ordering of memory,
i.e.\ starting multi-bytes data types with the most significant byte,
will not work since WebAssembly makes the assumption of a little-endian machine,
such as in the case of x86, ARM or RISC-V.

\subsection{No Dynamic Linking to OS Libraries}%
\label{sub:no_dynamic_linking}

Emscripten is at its core an LLVM backend (cf Figure~\ref{fig:llvm})
targetting the WebAssembly instruction set.
A WebAssembly module must run in isolation inside the browser
and thus needs access to every dependency inside the WebAssembly virtual machine.
Therefore, Emscripten requires the LLVM bitcode of every dependency used.
In traditional C and C++ environments however, we are used to depending on precompiled
shared dynamic libraries (.so and .dll files) provided by the OS packages.
To target WebAssembly, every dependency recursively, must be recompiled
by Emscripten from source code, and statically linked to our code.
To ease the process, Emscripten already includes most of the C and C++ the standard libraries,
in addition to few common libraries for graphical applications such as the SDL.

DVO~\cite{steinbrucker2011real} for example relies on OpenCV, Eigen, Boost and Sophus.
I tried to build a minimalist OpenCV program with Emscripten
and trouble began right from the start.
Unfortunately, OpenCV has only been partially ported to Wasm~\cite{taheri2018opencv}.
The porting team assumed that, in the context of the Web,
media would be generated from Web APIs.
Reading an image for example, is performed through the creation of an HTML canvas,
loading and decoding the image data, then transfered to an OpenCV matrix.
Native OpenCV however would use the \verb|imdecode| function,
itself depending on a dozen of other libraries such as libjpg, libtiff and libpng,
and not all have been ported to WebAssembly.
When trying to add the \verb|imdecode| function to the set of ported OpenCV code,
we currently hit ``missing symbol'' errors due to similar dependency and linking issues.
In the case of DVO and other RGB-D visual odometry algorithms,
there is a need to decode 16 bit PNGs for the depth images.
Until they are supported in Web APIs it won't be possible with OpenCV.

This limitation does not mean that DVO can never be ported to WebAssembly,
but that it would require a significant amount of work to either
complete the OpenCV port, or find another image decoding library
already ported to WebAssembly and adapt DVO code to accomodate it.
The same could happen for parts of Eigen, Boost and Sophus used in DVO.

\section{Rust and WebAssembly}%
\label{sec:rust_wasm}

\subsection{The Rust Programming Language}%
\label{sub:rust_language}

\begin{itemize}
	\item Algebraic data types
	\item Immutability by default
	\item Ownership
	\item Zero cost abstractions
\end{itemize}

\subsection{WebAssembly in Rust}%
\label{sub:wasm_in_rust}

https://rustwasm.github.io/docs/book/reference/crates.html

\begin{itemize}
	\item wasm-bindgen
	\item wasm-pack
	\item js-sys
	\item web-sys
\end{itemize}
