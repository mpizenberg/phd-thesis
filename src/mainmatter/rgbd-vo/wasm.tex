\chapter{Performant Web Applications}%
\label{cha:performant_web_applications}

\minitoc%
\clearpage

In the previous chapter we layed the foundation necessary
to modelize the visual odometry problem.
Similarly than in the first part of this thesis,
we want to explore an interactive scenario through the Web.
Visual odometry however, is slightly different from annotation
in terms of computational needs.
Before reviewing our library and interactive application,
we thus make a small detour toward an analysis of
performance capabilities in client Web applications.
Our tour starts with a brief history of ``native'' code in browsers,
followed by a detailed presentation of WebAssembly,
a recent technology about to change how we share and distribute
high performance code.
Finally we provide an explanation for the choice of the Rust
programming language for the development of our visual odometry library.

\section{A Brief History of Native Code in the Client}%
\label{sec:native_client}

Being able to run high performance code in the browser
is useful in many use cases, including for example scientific computing.
Yet, it remains a challenging task.
Resources often refer to this as ``native'' code
but the terminology is rather vague.
Depending on the context, ``native'' may have one of the following meanings,
\begin{enumerate}
\setlength\itemsep{-0.5em}
	\item code statically compiled directly to the target architecture and running from the browser,
	\item code compiled from a typical ``native'' language such as C or C++,
	\item or anything that is not generating JavaScript.
\end{enumerate}
The distinction between those and how they relate to ``native'' code
will be made clearer after the following
brief history of high performance code in browsers.

\subsection{Java Applets}%
\label{sub:java_applets}

In 1995, just four years after the birth of the Web,
the Java programming language was created.
It appeared along with a companion technology called Java Applet,
designed to run Java applications in the browser.
The Java Virtual Machine (JVM) was hosted by browsers,
enabling much better performances than JavaScript at that time.
As an example, Brendon C. Glazer worked on interactive ray tracing
of VRML scenes with Java applets in 1999~\cite{Glazer1999InteractiveRT}.
Figure~\ref{fig:glazer-thesis} depicts how the applet would appear
in a Web page at that time.
Since 1998 Java applets have also had access to 3D hardware acceleration~\cite{Java3dAPISpec}
whereas JavaScript waited until 2011 for WebGL in HTML5 canvas.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{assets/img/glazer-thesis.jpg}
	\caption{Interactive ray tracing applet from Brendon C. Glazer master thesis (1999).}%
	\label{fig:glazer-thesis}
\end{figure}

On the down side, Java applets would break accessibility of the Web.
Screen readers would not be able to parse the content of the dedicated
applet area in the page.
The security model of Java applets also had some weaknesses.
Applets would have to get approved by a browser user and then gain rights
equivalent to a native desktop application.
Unfortunately, just like terms of service,
most people click ``agree'' and move on~\cite{obar2018biggest}.
In addition, the Java Runtime Environment (JRE) has had hundreds of security
vulnerabilities~\cite{JreCve} in its lifetime.
This represents a serious security threat for browser vendors.
Java applets were eventually entirely removed from Java SE 11, in 2018.

\subsection{Flash}%
\label{sub:Flash}

In his ``History of Flash''~\cite{HistoryFlash}, Jonathan Gay retraces the early days of Flash.
In 1993, he, Charlie Jackson and Michelle Welsh founded FutureWave Software
but their initial vector drawing application did not draw much attention (pun intended).
After discussions at Siggraph 1995, the company decided to focus on a web animation
product named ``FutureSplash Animator''.
It gained reputation with Microsoft and Disney using it and as a consequence,
was acquired by Macromedia and rebranded ``Flash'' in 1996.

Contrary to Java applets, Flash use cases started very narrow.
It provided a simple and efficient solution to build and share animations on the web,
offering a visual advantage over pure HTML documents.
In year 2000, Flash 5 was released, with the ActionScript programming language,
bringing even more potential to Flash-based websites.
Two years later, in 2002, Flash 6 brought support for real-time messaging protocols,
enabling video and audio streaming capabilities.
This represents roughly 8 years until 2010 when such capabilities are also
supported through HTML5 in most browsers.
In the meantime, highly influencial projects shaped the Web thanks to Flash.
For example, Chad Hurley, Steve Chen and Jawed Karim launched
YouTube in 2005, based on Flash.

In spite of the many advantages of Flash and ActionScript over classic Web pages,
it also had similar flaws than Java applets.
In October 2000, usability consultant Jakob Nielsen published a short article
entitled ``Flash: 99\% Bad''~\cite{FlashBadNielsen} stating that
``Flash technology tends to discourage usability for three reasons:
it makes bad design more likely,
it breaks with the Web's fundamental interaction style,
and it consumes resources that would be better spent enhancing a site's core value.''
Apple also played a huge role in Flash decline.
In 2007 the iPhone launched without Flash support,
leading to Steve Jobs, then Apple CEO, writing in 2010 an oppen letter called
``Thoughts on Flash''~\cite{FlashJobs}
in which he explains why Flash was doomed to disappear.
Among those reasons, Flash is proprietary, going against open Web standards
and it has numerous security flaws~\cite{FlashCVE}.

Consequently, with the advent of HTML5 surrounding technologies regarding multimedia capabilities,
and the improved performances of JavaScript, Flash became obsolete.
So in July 2017, Adobe announced end support of Flash in 2020.

\subsection{Google Native Client (NaCl)}%
\label{sub:nacl}

Java applets and Flash were never trully considered ``native''
since they involved third party virtual machines.
One would not compile code directly to machine instructions
but to an intermediate bytecode representation for Java applets,
or just using a JIT compiler for ActionScript (Flash) code.
They provided however great performances improvements when compared
to JavaScript before 2008 and the arrival of JavaScript JIT compilers with the V8 engine.
But around 2009 and 2010, two new projects named Native Client (NaCl) and Emscripten
respectively emerged from research at Google and Mozilla.
We will hold on Emscripten for now and explain first what NaCl was about.

At this period of time, native code was already running in browsers,
usually via an old plugin interface called the ``Netscape Plugin API'' (NPAPI).
This is how the JVM, the Flash player or PDF readers for example
would be integrated in browsers.
So from the observation that the Web had trully become a rich multimedia platform,
and that native code was already running in browsers via plugins,
a team of Google engineers explored a way to generalize and improve security
of any native C or C++ code execution in browsers~\cite{yee2009native}.
This would in theory unlock high performances for any Web application.
But it would need a sandboxed and secure new set of APIs
to make sure that those applications would not execute any malicious code via the browser.
That is how the Native Client (NaCl) project,
and its associated API called Pepper Plugin API (PPAPI) started in 2009.

The two main downsides of this approach are the security and portability concerns.
Even though NaCl code would run into a sandboxed environment,
enforcing both security and accessibility to classical desktop resources
requires a continuous effort from browser vendors,
now needing to secure two different sandboxed environment,
NaCl and JavaScript, instead of one.
Portability was also a concern since any NaCl code would need to be compiled
to all target architectures where the browser need to run.
In practice, only x86 Intel architectures were fully supported,
going against the nature of the Web, supposed to run on all platforms.
This limitation was the reason for the birth of the Portable Native Client project.

Portable Native Client (PNaCl, pronounced like the word ``pinnacle''),
was a work by A. Donovan et al.~\cite{donovan2010pnacl} aiming at distributing
NaCl programs in an intermediate pre-compiled neutral instruction-set format,
preventing the need to compile directly to all target architectures.
Concretely, the format chosen was the Low-Level Virtual Machine (LLVM) bitcode.
Unfortunately, this intermediate representation bitcode is a fast moving target,
and retrocompatibility is not a main objective of the LLVM project.
It means that PNaCl code could become obsolete at a fast pace,
also a deal breaker for Web standards.
With the reluctance of other vendors to adopt a non-specified Google initiative,
and the appeal of another rising approach coming from Emscripten,
PNaCl was finally deprecated in 2017.

\subsection{Emscripten and asm.js}%
\label{sub:emscripten-asmjs}

Out of curiosity, Mozilla engineer Alon Zakai started to work around 2010
on a project to explore the limitations of compiling C++ code to JavaScript.
It was the start of the Emscripten project~\cite{zakai2011emscripten}.
Emscripten base idea consists in converting LLVM bitcode to JavaScript.
LLVM originated from the work of
Chris Lattner and Vikram Adve~\cite{lattner2004llvm} on a compiler framework
and an intermediate code representation, optimized for compiler transformations.
It reduces the language-architecture complexity from $\mathcal{O}(mn)$ to $\mathcal{O}(m+n)$
since languages do not need to compile to every target like x86 or Arm,
and instead can just target LLVM which in turn knows how to compile to each
instruction set architecture (ISA) as depicted in Figure~\ref{fig:llvm}.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{assets/img/llvm.pdf}
	\caption{LLVM Compiler Infrastructure}%
	\label{fig:llvm}
\end{figure}

After few iterations with the help of Luke Wagner, working on JavaScript compilation at Mozilla,
Emscripten was able to output JavaScript code
running roughly two to three times slower than the equivalent C code.
This specific subset of JavaScript was formalized under the name asm.js in 2013~\cite{herman2013asm}.
The asm.js code for a sum function is presented in Listing~\ref{lst:add-asmjs}.
As you can see, it makes use of JavaScript operations doing nothing,
like the bitwise-or with 0, except cohercing values to certain types.
You would not want to write asm.js code by hand, but for a compiler,
it enables certain kinds of optimizations not possible with traditional
hand-written JavaScript code.
Yet it is a strict subset of JavaScript and can still run in any browser,
whether or not they have a specialized handling of asm.js.

\lstinputlisting[%
	language=JavaScript,
	caption={Sum of two 32-bit integers in asm.js.},
	label={lst:add-asmjs}
]{assets/code/add-asm.js}

The performances without the need of any plugin convinced companies with huge
code bases to join the effort.
The Unreal game engine was ported~\cite{unrealweb},
Autodesk AutoCAD~\cite{autocadweb},
Adobe Lightroom~\cite{lightroomweb},
OpenCV~\cite{taheri2018opencv} and many others.
With the success of Emscripten and asm.js as a proof of concept,
all major browser vendors came together to formalize a new specification
known today as WebAssembly.
Figure~\ref{fig:wasm-timeline} summarizes main events leading to the creation of WebAssembly.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{assets/img/wasm-timeline.pdf}
	\caption{Events releated to the birth of WebAssembly.}%
	\label{fig:wasm-timeline}
\end{figure}

\section{WebAssembly}%
\label{sec:WebAssembly}

WebAssembly, abreviated Wasm, is an instruction set with a binary format,
and a stack-based virtual machine able to execute those programs~\cite{haas2017bringing}.

\subsection{Relation to Previous Technologies}%
\label{sub:wasm_previous}

Just like Flash and Java applets, WebAssembly code
is executed by a virtual machine.
Similarly to NaCl, the Wasm runtime is sandboxed,
preventing it from accessing data outside of its context
and compromising the security of the underlying machine.
And as asm.js, Wasm does not require any plugin.
It has been developed as a Web standard and implemented
by all major Web browsers, desktop and mobile, since 2017.
Unlike asm.js however, Wasm is distributed in a binary format,
meaning it is more efficient to send over the network and to parse,
drastically reducing the loading time of Web pages.
WebAssembly has been built drawing lessons from the past and is likely to endure
for the following reasons.

\begin{itemize}
	\item It is a Web standard and a collective effort from all browser vendors.
	\item It is the low level missing piece of the Web,
		complementing JavaScript where more control over performances is needed.
	\item It offers strong security guaranties, and a sound type system~\cite{watt2018mechanising}.
	\item It theoretically enables any programming language to run on the Web.
\end{itemize}

\subsection{Compilation to WebAssembly}%
\label{sub:compile-wasm}

Currently WebAssembly does not provide a garbage collector.
Therefore, there are two main approaches to compile to WebAssembly.
If a programming language enables memory management at compile time,
such as C, C++ or Rust, the simplest way is to target LLVM intermediate representation.
Emscripten enables compilation to WebAssembly from C and C++.
Rust can either use Emscripten as a backend or directly the wasm32 target of LLVM.\@
Otherwise, when a programming language requires a runtime for features such as garbage collection,
the entire runtime needs to be ported to WebAssembly in addition to the actual program.
This is for example the case of Blazor, a .NET (Microsoft) library
enabling the creation of Single Page Applications written in C\#.

\subsection{WebAssembly Minimum Viable Product (MVP)}%
\label{sub:wasm-mvp}

The first version of WebAssembly, initially released on March 2017,
is called a minimum viable product (MVP).
This consensus aimed at producing a simple yet functional specification and implementation
for all major browser vendors.
Concretely, the Wasm MVP offers roughly the same capabilities than asm.js.
It has only four types, integers and floating point numbers in 32 and 64 bits,
and manages memory as a unique contiguous block of bytes.
New features such as threads,
SIMD, exception handling, reference types, garbage collection or tail call optimization,
are currently being worked on and delayed to the after-MVP phase.

\subsection{WebAssembly Bright Future}%
\label{sub:wasm-future}

A common pun in WebAssembly communities is to describe it
as ``neither Web, nor assembly''~\cite{jayphelps2019wasm}.
Although slightly caricatural, the WebAssembly specification does not require any Web component.
As a matter of fact, just like JavaScript broke out of the browser with Node,
many non-browser WebAssembly runtimes have already been created, such as Wasmer~\cite{wasmer}
and Wasmtime~\cite{wasmtime}.

Since Wasm is basically a performant sandboxed calculator,
interoperability capabilities with files or the network
must be provided in the form of imports and exports of a Wasm module.
In the browser, those are passed to the module at the initialization call from JavaScript.
But outside of the browser, as in Wasmer for example,
imports and exports have to be provided by the runtime environment.
If we want to be able to use the same Wasm module in those two different contexts,
we need to have a common interface specification,
which can have different implementations in each runtime environment.

In order to adress those points, the WebAssembly working group
is standardizing a system interface under the name
WebAssembly System Interface (WASI~\cite{wasi}) and a types interface
known as WebAssembly Interface Types~\cite{wait}.
As shown in the demonstration video available on YouTube~\cite{waitvideo},
it is now possible to create a Wasm library in Rust for example,
and then call it from the Web, Node, Rust, but even Python or any language
capable of embedding a WebAssembly runtime.

\subsection{Why this Matters for Research}%
\label{sub:matter-research}

A growing number of actors are worrying about research
reproducibility~\cite{claerbout1992electronic, buckheit1995wavelab}
in computational sciences.
Nick Barnes published an article on Nature News~\cite{barnes2010publish}
encouraging researchers to publish even bad code instead of none.

IPOL Journal~\cite{limare2011ipol}, Image Processing On Line, is an initiative supported by
the French space agency CNES and the European Research Council.
Its goal is to publish both precise algorithm descriptions and certified implementations,
and making them available on an online platform.
Due to performance constraints, they rejected most garbage collected languages
interpreted or based on virtual machines such as Python and Java,
and only accept Fortran, C and C++ implementations with strict portability requirements.
In order to mitigate security risks, authors are uniquely identified.
Exposure to malicious data, such as images uploaded by online users,
is reduced by system restrictions and careful examination of the source code during review.
WebAssembly would have been a perfect fit for this project if it had existed in 2010
since it provides a solution for secure, performant and portable code.

The Association for Computing Machinery (ACM) recently revised its
artifact review and badging policies~\cite{acm2018badging},
based on the International Vocabulary for Metrology.
A work is considered repeatable if the results are obtainable on multiple trials,
within the same team and experimental setup.
It is considered replicable if another team is capable of getting the same results
while reusing the provided artifact and same experimental setup.
Finally it is considered reproducible if the results can be reproduced
with different teams and experimental setup, without using the provided artifacts.
In accordance to these guidelines, ACM Multimedia, the ACM conference targetting multimedia
research, has setup a reproducibility review process,
based on companion papers~\cite{acmmmreproducibility}.
Companion papers are distinct from the main paper.
They must be provided with associated artifacts and describe precisely
how to replicate the findings of the associated original paper contribution.

Containarization of the development environment with tools such as Docker
is a new practice reducing dependency conflicts.
It has been picked up by the machine learning community,
especially when needing to use different versions of languages and tools
for deep learning tasks in separate projects.
Carl Boettiger even wrote a paper entitled
``An introduction to Docker for reproducible research''~\cite{boettiger2015introduction}
describing the different aspects of computer environments preventing work reproducibility.
Yet, Solomon Hykes, the original author of Docker shared on twitter that
if WebAssembly and its system interface existed in 2008, he wouldn't have
needed to create Docker~\cite{hykes2019twitter}. ``That's how important it is'' as he said.

\section{C++ Portability Pitfalls}%
\label{sec:cpp_pitfalls}

Not every C or C++ project can be ported to WebAssembly.
There are three main factors of non portability:
Web limitations, no low-level architecture specific code and no system dynamic linking.

\subsection{Web Limitations}%
\label{sub:web_limitations}

High performance code may rely on parallelization to speed up processing.
Due to security concerns, parallelization methods such as multithreading
or SIMD are currently a work in progress but not usable by default in browsers.

\subsection{Low Level Native or Architecture Specific Code}%
\label{sub:low_level_code}

Other high performance code may rely on architecture specific constraints.
For example, x86 assembly is not portable to other platforms.
Code requiring a big-endian physical ordering of memory,
i.e.\ starting multi-bytes data types with the most significant byte,
will not work since WebAssembly makes the assumption of a little-endian machine,
such as in the case of x86, ARM or RISC-V.

\subsection{No Dynamic Linking to OS Libraries}%
\label{sub:no_dynamic_linking}

Emscripten is at its core an LLVM backend (cf Figure~\ref{fig:llvm})
targetting the WebAssembly instruction set.
A WebAssembly module must run in isolation inside the browser
and thus needs access to every dependency inside the WebAssembly virtual machine.
Therefore, Emscripten requires the LLVM bitcode of every dependency used.
In traditional C and C++ environments however,
it is common practice to depend on precompiled
shared dynamic libraries (.so and .dll files) provided by the OS packages.
In contrast, Emscripten needs the source code of every direct
and transitive dependency to produce the LLVM bitcode and then the Wasm code.
To ease the process, Emscripten already includes most of the C and C++ standard libraries,
in addition to few common libraries for graphical applications such as
Simple DirectMedia Layer (SDL), a cross-platform multimedia library.

DVO~\cite{steinbrucker2011real} for example relies on OpenCV, Eigen, Boost and Sophus.
Unfortunately, OpenCV has only been partially ported to WebAssembly~\cite{taheri2018opencv}.
The porting team assumed that, in the context of the Web,
media would be generated from Web APIs.
Reading an image for example, is performed through the creation of an HTML canvas,
loading and decoding the image data, which is then transferred to an OpenCV matrix.
Native OpenCV however would use the \verb|imdecode| function,
itself depending on a dozen of other libraries such as libjpg, libtiff and libpng,
not all of which have been ported to WebAssembly.
When trying to add the \verb|imdecode| function to the set of ported OpenCV code,
one currently hits ``missing symbol'' errors due to similar dependency and linking issues.
In the case of DVO and other RGB-D visual odometry algorithms,
there is a need to decode 16 bit PNGs for the depth images.
Until they are supported in Web APIs it will not be possible with OpenCV.

This limitation does not mean that DVO can never be ported to WebAssembly,
but that it would require a significant amount of work to either
complete the OpenCV port, or find another image decoding library
already ported to WebAssembly and adapt DVO code to accomodate it.
The same could happen for parts of Eigen, Boost and Sophus used in DVO.

\section{Rust and WebAssembly}%
\label{sec:rust_wasm}

WebAssembly and the Rust programming language are both technologies
that emerged from research projects at Mozilla.
Though independent, their core communities are thus sharing similar values
and working in synergy within the Rust and WebAssembly Working Group.

\subsection{The Rust Programming Language}%
\label{sub:rust_language}

Rust is a programming language focused on safety, speed and concurrency,
that begun in 2006 as a side project by Mozilla employee Graydon Hoare.
It has been evolving drastically until 2015, when version 1.0 was announced
with stability goals in mind.
There are many reasons why Rust is among the best contestants
for writing efficient and correct computer vision algorithms.
We will focus on those related to our task,
interactive computer vision on the web.

First, Rust uses an LLVM backend so it is capable of targetting WebAssembly by default.
In addition, Rust has an automatic memory management system called ownership.
It enables memory safety guarantees at compile time
without the need of a garbage collector or manual memory management.
This is important in the context of WebAssembly since it means that Rust code
can be compiled to Wasm without embedding a big runtime for memory management.
Ownership in Rust is based on the concept of linear types,
highly influenced by the work of Girard~\cite{girard1987linear},
Wadler~\cite{wadler1991there}, Baker~\cite{baker1992lively},
and Clark et al.~\cite{clarke1998ownership} among others.
The main idea behind Rust ownership is that every value has
a unique variable called its owner.
When this variable goes out of scope, the associated value is released from memory.
Other variables can access this value during its lifetime
through a borrowing mechanism, similar to references.
At any time, there must be at most one mutable borrow,
and there cannot be mutable and immutable borrows at the same time.
Those constraints are very similar to the read and write constraints
usually enforced on shared values in concurrent programming.

Finally Rust is not affected by the dynamic linking issues
we mentioned earlier when targetting WebAssembly in C++.
Rust 1.0 shipped with a project manager called ``cargo''
and an online package registry ``crates.io''.
Cargo manages compilation, modules and external dependencies
with the use of a very simple project description file named \verb|Cargo.toml|
placed at the root of a Rust project.
As a consequence, compiling a pure Rust project will almost always work
with a single command \verb|cargo build|.
It downloads dependencies, locally build and statically link them.

In contrast to the Elm package registry we discussed in Section~\ref{sub:reliable_packages},
Rust packages follow but do not enforce semantic versioning.
Similarly to Elm, Rust also provides algebraic data types with pattern matching,
and immutability by default, thus giving much more confidence than C++
that when a program compiles it is correct.

\subsection{WebAssembly in Rust}%
\label{sub:wasm_in_rust}

The WebAssembly tooling ecosystem in Rust is composed of four main projects.
\begin{itemize}
	\item \verb|wasm-bindgen|~\cite{wasmbindgen} facilitates interoperability
		between Rust and JavaScript with the help of simple code annotations.
	\item \verb|wasm-pack|~\cite{wasmpack} complements \verb|wasm-bindgen|
		by generating all the JavaScript glue code currently necessary to load and call
		a WebAssembly module from JavaScript as if it was an ES6 module.
		\verb|wasm-pack build| basically serves as a replacement to
		\verb|cargo build| when compiling to WebAssembly.
	\item \verb|js-sys|~\cite{jssys} provides raw bindings to JavaScript global APIs
		for projects using wasm-bindgen.
	\item \verb|web-sys|~\cite{websys} provides raw bindings to Web APIs
		for projects using wasm-bindgen.
\end{itemize}

Out of those four projects, \verb|wasm-pack| is considered a tool,
installed alongside the rest of Rust tooling.
The three others simply are libraries, added to a project dependencies
with one line each in the description file \verb|Cargo.toml|.

\section{Conclusion}%
\label{sec:cclwasm}

The Web is in constant evolution.
It is also the most ubiquitous platform, accessible from multitude of devices
such as laptops, tablets, phones and embedded devices.
Being able to run performant code in Web browsers has thus being a competitive advantage,
and many technologies have tried to corner that market.
As we explained however, all those past technologies such as Java applets,
Flash or Google NaCl have had huge drawbacks, preventing them from standard adoption.
Recently with the arrival of WebAssembly, we finally arrived at a point where high performance
code can run in Web browsers with very few inconvenients.
For this reason, the four major browser vendors, Google, Mozilla, Microsoft and Apple
all rallied together to define this new standard and implement a minimum viable product in few months.
We also explained why the current best two languages to target WebAssembly are C++ and Rust.
While C++ has the original WebAssembly code generator available, called Emscripten,
the language struggles with building dependencies and legacy non portable code.
Combined with the intrinsic difficulties of that language to safely build on
other contributions, we decided to avoid C++ and start fresh with the Rust programming language.
We can also note that in 2019, for the fourth year in a row,
Rust has been elected the most loved programming language
by respondents of the Stack Overflow's annual developer survey~\cite{rustlovedso}.
So we hope that this choice will also bring more joy to potential future contributors.
In the next chapter, we will thus introduce our visual odometry library in Rust
and present its port to an interactive Web application.
