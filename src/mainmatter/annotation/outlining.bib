@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3431--3440},
  year={2015}
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}

@inproceedings{papandreou2015weakly,
  title={Weakly-and Semi-Supervised Learning of a Deep Convolutional Network for Semantic Image Segmentation},
  author={Papandreou, George and Chen, Liang-Chieh and Murphy, Kevin P and Yuille, Alan L},
  booktitle={Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
  pages={1742--1750},
  year={2015},
  organization={IEEE Computer Society}
}

@article{liu2017active,
  title={Active deep learning for classification of hyperspectral images},
  author={Liu, Peng and Zhang, Hui and Eom, Kie B},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={10},
  number={2},
  pages={712--724},
  year={2017},
  publisher={IEEE}
}

@article{russell2008labelme,
  title={LabelMe: a database and web-based tool for image annotation},
  author={Russell, Bryan C and Torralba, Antonio and Murphy, Kevin P and Freeman, William T},
  journal={International journal of computer vision},
  volume={77},
  number={1},
  pages={157--173},
  year={2008},
  publisher={Springer}
}

@inproceedings{mortensen1995intelligent,
  title={Intelligent scissors for image composition},
  author={Mortensen, Eric N and Barrett, William A},
  booktitle={Proceedings of the 22nd annual conference on Computer graphics and interactive techniques},
  pages={191--198},
  year={1995},
  organization={ACM}
}

@article{wang2007soft,
 author = {Wang, Jue and Agrawala, Maneesh and Cohen, Michael F.},
 title = {Soft Scissors: An Interactive Tool for Realtime High Quality Matting},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2007},
 volume = {26},
 number = {3},
 month = jul,
 year = {2007},
 issn = {0730-0301},
 articleno = {9},
 url = {http://doi.acm.org/10.1145/1276377.1276389},
 doi = {10.1145/1276377.1276389},
 acmid = {1276389},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{rother_grabcut:_2004,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '04},
	title = {"{GrabCut}": {Interactive} {Foreground} {Extraction} {Using} {Iterated} {Graph} {Cuts}},
	shorttitle = {"{GrabCut}"},
	url = {http://doi.acm.org/10.1145/1186562.1015720},
	doi = {10.1145/1186562.1015720},
	abstract = {The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for "border matting" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.},
	urldate = {2016-10-12},
	booktitle = {{ACM} {SIGGRAPH} 2004 {Papers}},
	publisher = {ACM},
	author = {Rother, Carsten and Kolmogorov, Vladimir and Blake, Andrew},
	year = {2004},
	keywords = {Alpha Matting, Foreground extraction, Graph Cuts, Image Editing, interactive image segmentation},
	pages = {309--314},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/U2MNPCUZ/Rother et al. - 2004 - GrabCut Interactive Foreground Extraction Using.pdf:application/pdf}
}

@inproceedings{boykov_interactive_2001,
	title = {Interactive graph cuts for optimal boundary amp; region segmentation of objects in {N}-{D} images},
	volume = {1},
	doi = {10.1109/ICCV.2001.937505},
	abstract = {In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as “object” or “background” to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both “object” and “background” segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm},
	booktitle = {Eighth {IEEE} {International} {Conference} on {Computer} {Vision}, 2001. {ICCV} 2001. {Proceedings}},
	author = {Boykov, Y. Y. and Jolly, M. P.},
	year = {2001},
	keywords = {Biomedical imaging, computational geometry, Cost function, Educational institutions, Gestalt example, globally optimal segmentation, hard constraints, Image segmentation, interactive graph cuts, interactive segmentation, interactive systems, Level set, max-flow algorithm, medical image segmentation, N-D images, N-dimensional images, optimal boundary \& region segmentation, Region 5, soft constraints, Topology, Visualization},
	pages = {105--112 vol.1},
	file = {IEEE Xplore Abstract Record:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/VVXAINTP/937505.html:text/html}
}

@article{mcguinness2010comparative,
  title={A comparative evaluation of interactive segmentation algorithms},
  author={McGuinness, Kevin and O’connor, Noel E},
  journal={Pattern Recognition},
  volume={43},
  number={2},
  pages={434--444},
  year={2010},
  publisher={Elsevier}
}

@article{salembier2000binary,
  title={Binary partition tree as an efficient representation for image processing, segmentation, and information retrieval},
  author={Salembier, Philippe and Garrido, Luis},
  journal={IEEE transactions on Image Processing},
  volume={9},
  number={4},
  pages={561--576},
  year={2000},
  publisher={IEEE}
}

@inproceedings{batra_icoseg:_2010,
	title = {{iCoseg}: {Interactive} co-segmentation with intelligent scribble guidance},
	shorttitle = {{iCoseg}},
	doi = {10.1109/CVPR.2010.5540080},
	abstract = {This paper presents an algorithm for Interactive Co-segmentation of a foreground object from a group of related images. While previous approaches focus on unsupervised co-segmentation, we use successful ideas from the interactive object-cutout literature. We develop an algorithm that allows users to decide what foreground is, and then guide the output of the co-segmentation algorithm towards it via scribbles. Interestingly, keeping a user in the loop leads to simpler and highly parallelizable energy functions, allowing us to work with significantly more images per group. However, unlike the interactive single image counterpart, a user cannot be expected to exhaustively examine all cutouts (from tens of images) returned by the system to make corrections. Hence, we propose iCoseg, an automatic recommendation system that intelligently recommends where the user should scribble next. We introduce and make publicly available the largest co-segmentation datasetyet, the CMU-Cornell iCoseg Dataset, with 38 groups, 643 images, and pixelwise hand-annotated groundtruth. Through machine experiments and real user studies with our developed interface, we show that iCoseg can intelligently recommend regions to scribble on, and users following these recommendations can achieve good quality cutouts with significantly lower time and effort than exhaustively examining all cutouts.},
	booktitle = {2010 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Batra, D. and Kowdle, A. and Parikh, D. and Luo, J. and Chen, T.},
	month = jun,
	year = {2010},
	keywords = {automatic recommendation system, energy functions, Facebook, foreground object, iCoseg, Image segmentation, intelligent scribble guidance, Intelligent systems, interactive cosegmentation, interactive object-cutout literature, Iterative algorithms, Machine intelligence, recommender systems, Smart pixels, unsupervised cosegmentation},
	pages = {3169--3176},
	file = {IEEE Xplore Abstract Record:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/HEEH2ZUF/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/VI3N8PW7/Batra et al. - 2010 - iCoseg Interactive co-segmentation with intellige.pdf:application/pdf}
}

@inproceedings{carlier_clickncut:_2014,
	address = {New York, NY, USA},
	series = {{CrowdMM} '14},
	title = {Click'{N}'{Cut}: {Crowdsourced} {Interactive} {Segmentation} with {Object} {Candidates}},
	isbn = {978-1-4503-3128-9},
	shorttitle = {Click'{N}'{Cut}},
	url = {http://doi.acm.org/10.1145/2660114.2660125},
	doi = {10.1145/2660114.2660125},
	abstract = {This paper introduces Click'n'Cut, a novel web tool for interactive object segmentation designed for crowdsourcing tasks. Click'n'Cut combines bounding boxes and clicks generated by workers to obtain accurate object segmentations. These segmentations are created by combining precomputed object candidates in a light computational fashion that allows an immediate response from the interface. Click'n'Cut has been tested with a crowdsourcing campaign to annotate images from publicly available datasets. Results are competitive with state-of-the-art approaches, especially in terms of time needed to converge to a high quality segmentation.},
	urldate = {2016-10-15},
	booktitle = {Proceedings of the 2014 {International} {ACM} {Workshop} on {Crowdsourcing} for {Multimedia}},
	publisher = {ACM},
	author = {Carlier, Axel and Charvillat, Vincent and Salvador, Amaia and Giro-i-Nieto, Xavier and Marques, Oge},
	year = {2014},
	keywords = {crowdsourcing, object candidates, object segmentation},
	pages = {53--56},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/8HDBXXI5/Carlier et al. - 2014 - Click'N'Cut Crowdsourced Interactive Segmentation.pdf:application/pdf}
}

@article{carlier2016assessment,
  title={Assessment of crowdsourcing and gamification loss in user-assisted object segmentation},
  author={Carlier, Axel and Salvador, Amaia and Cabezas, Ferran and Giro-i-Nieto, Xavier and Charvillat, Vincent and Marques, Oge},
  journal={Multimedia tools and applications},
  volume={75},
  number={23},
  pages={15901--15928},
  year={2016},
  publisher={Springer}
}

@inproceedings{chavez2013crowdsourcing,
  title={A crowdsourcing web platform-hip joint segmentation by non-expert contributors},
  author={Ch{\'a}vez-Arag{\'o}n, Alberto and Lee, Won-Sook and Vyas, Aseem},
  booktitle={Medical Measurements and Applications Proceedings (MeMeA), 2013 IEEE International Symposium on},
  pages={350--354},
  year={2013},
  organization={IEEE}
}

@inproceedings{gurari2015collect,
  title={How to collect segmentations for biomedical images? A benchmark evaluating the performance of experts, crowdsourced non-experts, and algorithms},
  author={Gurari, Danna and Theriault, Diane and Sameki, Mehrnoosh and Isenberg, Brett and Pham, Tuan A and Purwada, Alberto and Solski, Patricia and Walker, Matthew and Zhang, Chentian and Wong, Joyce Y and others},
  booktitle={Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on},
  pages={1169--1176},
  year={2015},
  organization={IEEE}
}

@inproceedings{irshad2014crowdsourcing,
  title={Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd.},
  author={Irshad, Humayun and Montaser-Kouhsari,  Laleh and Waltz, Gail and Bucur, Octavian and Nowak, JA and Dong,  Fei and Knoblauch,  Nicholas W and Beck, Andrew H},
  booktitle={Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
  pages={294--305},
  year={2014},
  organization={NIH Public Access}
}

@inproceedings{korinke_intuitive_2015,
	address = {New York, NY, USA},
	series = {{MM} '15},
	title = {Intuitive {Input} {Methods} for {Interactive} {Segmentation} on {Mobile} {Touch}-{Based} {Devices}},
	isbn = {978-1-4503-3459-4},
	url = {http://doi.acm.org/10.1145/2733373.2807993},
	doi = {10.1145/2733373.2807993},
	abstract = {Existing interactive image segmentation approaches mainly focus on the algorithms rather than the input methods. The literature regarding the input methods is mainly applied to desktop PCs. However, there is a transition to mobile touch-based devices. In this paper we describe our approach to identify a set of intuitive input methods for interactive segmentation on mobile devices. Preliminary results of two user studies are presented. A description of our planned research is given, divided into initial and refinement input methods and the exploitation of the input for segmentation algorithms.},
	urldate = {2016-10-12},
	booktitle = {Proceedings of the 23rd {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Korinke, Christoph},
	year = {2015},
	keywords = {input methods evaluation, interactive image segmentation, mobile touch-based devices},
	pages = {645--648},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/6PE7B6ZX/Korinke - 2015 - Intuitive Input Methods for Interactive Segmentati.pdf:application/pdf}
}

@inproceedings{korinke_exploring_2015,
	address = {New York, NY, USA},
	series = {{MUM} '15},
	title = {Exploring {Touch} {Interaction} {Methods} for {Image} {Segmentation} on {Mobile} {Devices}},
	isbn = {978-1-4503-3605-5},
	url = {http://doi.acm.org/10.1145/2836041.2836049},
	doi = {10.1145/2836041.2836049},
	abstract = {Photo taking is more and more moving to mobile devices. With this transition, we observe that consumers are also directly editing and sharing photos. Editing of the whole image became very popular, for example with the filters Instagram offers. Some effects, however, require to edit a specific object of an image and for this an interactive segmentation is needed. This process is still tedious, as existing segmentation approaches focus on the algorithms rather than on the input methods. This paper explores different interaction techniques for image segmentation on mobile devices. We conducted two studies. The first to identify intuitive input methods and the second to evaluate the findings of the first study. As a result, we identified preferred gestures for the initial step to select a foreground object in an interactive image segmentation process. The results give first insights which input methods users intuitively use, how the users behave and what are the problems of the methods. This insights should be taken in consideration by the development of new interactive segmentation algorithms for mobile touch-based devices.},
	urldate = {2016-10-12},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {ACM},
	author = {Korinke, Christoph and Worzyk, Nils Steffen and Boll, Susanne},
	year = {2015},
	keywords = {bounding box, colouring, input methods evaluation, interactive image segmentation, mobile touch-based devices, outline},
	pages = {84--93},
	file = {ACM Full Text PDF:/home/acarlier/.zotero/zotero/ip4o5zz4.default/zotero/storage/V4Z9PEZK/Korinke et al. - 2015 - Exploring Touch Interaction Methods for Image Segm.pdf:application/pdf}
}

@article{comaniciu2002mean,
  title={Mean shift: A robust approach toward feature space analysis},
  author={Comaniciu, Dorin and Meer, Peter},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={24},
  number={5},
  pages={603--619},
  year={2002},
  publisher={IEEE}
}

@article{blum1978shape,
  title={Shape description using weighted symmetric axis features},
  author={Blum, Harry and Nagel, Roger N},
  journal={Pattern recognition},
  volume={10},
  number={3},
  pages={167--180},
  year={1978},
  publisher={Elsevier}
}

@book{nielsen1994usability,
  title={Usability engineering},
  author={Nielsen, Jakob},
  year={1994},
  publisher={Elsevier}
}
